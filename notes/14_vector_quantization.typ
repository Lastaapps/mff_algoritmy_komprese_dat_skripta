#import "../definitions.typ": *

#pagebreak()

= Vector Quantization

== Introduction to Vector Quantization
Vector Quantization (VQ) is a lossy compression technique that extends the concept of scalar quantization to multiple dimensions. Instead of quantizing individual samples (like in scalar quantization), VQ groups input samples into vectors and quantizes the entire vector at once.

*Key Idea*:
- Group input samples into vectors of a fixed dimension $L$. For example, a block of $n times m$ pixels in an image can form a vector of dimension $L = n times m$.
- A *codebook* is maintained, which consists of a set of pre-selected representative vectors called *code-vectors*.
- For each input vector, the encoder finds the closest code-vector in the codebook and transmits the *binary index* of that code-vector.
- The decoder uses this index to look up the corresponding code-vector in its identical codebook for reconstruction.

== Vector Quantization Procedure
1. *Encoder*:
  a.  Takes an L-dimensional source vector.
  b.  Searches the codebook to find the code-vector that is "closest" (minimizes a distortion measure, typically Mean Squared Error).
  c.  Transmits the index of this best-matching code-vector.
2. *Decoder*:
  a.  Receives the index.
  b.  Looks up the code-vector at that index in its codebook.
  c.  Outputs this code-vector as the reconstructed vector.

*Compression Performance*:
- *Rate (bits/sample)*: Given a codebook of size $K$ and vector dimension $L$, the rate is $R = (ceil(log_2 K)) / L$.
- *Distortion*: The "closeness" of vectors is measured by a distance function, most commonly the squared Euclidean distance (mean squared error).

#figure(
  image("../figures/14-vector_quantization_procedure.png", width: 80%),
  caption: "The vector quantization procedure.",
)

== Codebook Design: The LBG Algorithm
The quality of VQ heavily depends on the quality of the codebook. The LBG algorithm (Linde-Buzo-Gray, 1980) is a well-known iterative algorithm for designing a good codebook from a large set of training vectors. It is essentially an application of the k-means clustering algorithm.

#info_box(title: "LBG Algorithm Steps", [
  1. *Initialization*: Start with an initial codebook of $K$ code-vectors.
  2. *Quantization Region Partitioning*: Assign each vector from the training set to the region of its closest code-vector. This partitions the training set into $K$ clusters.
  3. *Codebook Update*: Update each code-vector by computing the centroid (average) of all training vectors in its assigned region.
  4. *Iteration*: Repeat steps 2 and 3 until the average distortion between the training vectors and their representative code-vectors converges (i.e., the change in distortion falls below a small threshold).
])

*Initialization Techniques for LBG*:
- *Splitting Technique*: Start with a single code-vector (the centroid of the entire training set). Iteratively split this code-vector into two by adding a small perturbation vector, run LBG to get two optimal code-vectors, and repeat this splitting process until the desired number of code-vectors is reached.
- *Pairwise Nearest Neighbor (PNN)*: Start with a codebook where each training vector is its own code-vector. Iteratively merge the two "closest" code-vectors (the pair that results in the smallest increase in distortion) until the desired codebook size is reached.

== Improving VQ Search Speed: TSVQ
A full search of a large codebook can be computationally expensive. Tree-Structured Vector Quantization (TSVQ) organizes the codebook into a binary tree to accelerate the search.

- *Structure*: The codebook is hierarchically partitioned. Each node in the tree represents a subset of the code-vectors, with the root representing the entire codebook and the leaves representing individual code-vectors.
- *Search*: An input vector is quantized by traversing the tree from the root. At each node, a simple comparison determines which of the two child nodes to descend to. The path taken through the tree determines the output codeword (binary string).
- *Pros*: Drastically reduces the number of comparisons from $K$ to approximately $2 \cdot log_2 K$.
- *Cons*: Increased storage is required (to store test vectors at each node), and the resulting distortion is typically higher than with a full search VQ.
- *Pruned TSVQ*: A variation that prunes subtrees to improve the rate-distortion trade-off, creating variable-length binary codewords.

== Other VQ Techniques

- *Lattice Vector Quantization (LVQ)*: Uses code-vectors that are points on a regular, structured lattice. This avoids the need for a training set and codebook storage, as the code-vectors are generated by a mathematical formula. The G.719 audio coding standard uses a quantizer based on the $D_8$ lattice.

#figure(
  image("../figures/14-lattice_A2_quantizer.png", width: 80%),
  caption: "Lattice A2 quantizer.",
)

#figure(
  image("../figures/14-lattice_D2_quantizer.png", width: 80%),
  caption: "Lattice D2 quantizer.",
)
- *Classified Vector Quantization (CVQ)*: Divides source vectors into different classes based on their properties (e.g., in images, "edge" blocks vs. "non-edge" blocks). A separate, specialized codebook is used for each class, which can improve efficiency.

== Applications
Vector quantization is a fundamental technique in modern lossy compression, used in:
- *Audio*: G.719, CELP (Code-Excited Linear Prediction), Vorbis, TwinVQ.
- *Video*: QuickTime (Apple), VQA (Westwood Studios).
